{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check for Colab Env\n",
    "> if we are in colab env we need to get the data + scripts from github or somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    _useMultiProcessing = False\n",
    "else:\n",
    "    _useMultiProcessing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- enable module autoreload and fix an import bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd() + '/scripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- import the scripts and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import data, model\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create the model and compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = model.get_do_unet()\n",
    "\n",
    "unet.compile(optimizer=\"adam\",\n",
    "             loss=\"binary_crossentropy\",\n",
    "             loss_weights=[0.3, 0.7],\n",
    "             metrics=[\"acc\"])\n",
    "\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_files = glob.glob('data/train/*.jpg')\n",
    "test_img_files = glob.glob('data/test/*.jpg')\n",
    "\n",
    "train = model.generate_train_dataset(train_img_files)\n",
    "\n",
    "train_generator = model.generate_train_dataset(train_img_files)\n",
    "\n",
    "train_set = model.generate_train_dataset_tf(train_img_files)\n",
    "\n",
    "test_img_chips, test_mask_chips, test_edge_chips = model.generate_test_dataset(test_img_files)\n",
    "\n",
    "test_set = tf.data.Dataset.from_tensor_slices((test_img_chips, (test_mask_chips, test_edge_chips)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- slice each image to small samples of size 188*188\n",
    "- imgs -> rgb image\n",
    "- mask -> mask\n",
    "- edge -> edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_chips, (train_mask_chips, train_edge_chips) =  next(train_generator)\n",
    "\n",
    "ind = 200\n",
    "fig = plt.figure(figsize=(15, 10), dpi=80)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "ax.imshow(train_img_chips)\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "ax.imshow(train_mask_chips)\n",
    "ax = fig.add_subplot(2, 3, 3)\n",
    "ax.imshow(train_edge_chips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_size = 8\n",
    "_epochs = 4\n",
    "_workers = 8\n",
    "_model_name = 'A'\n",
    "\n",
    "train_steps = len(train_img_files)//_batch_size\n",
    "validation_steps = len(test_img_files)//_batch_size\n",
    "\n",
    "unet.fit(train_set.batch(_batch_size), \n",
    "         epochs=_epochs, \n",
    "         validation_data=test_set.batch(_batch_size), \n",
    "         steps_per_epoch=train_steps,\n",
    "         max_queue_size=2*_workers,\n",
    "         use_multiprocessing=_useMultiProcessing,\n",
    "         workers=_workers,\n",
    "         verbose=1,\n",
    "         callbacks=model.get_callbacks(_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_img_chips[np.random.randint(0, len(test_img_chips), 1)[0]]\n",
    "\n",
    "img = np.array([np.squeeze(img)])\n",
    "\n",
    "\n",
    "prediction = unet.predict(img)\n",
    "\n",
    "np.array(prediction).min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 5, 1)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c475343c90b37f20c02fd3a18d45f7c3e275848f34e4c07d7554fbf081374c3b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
